{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Window size: 1, 7, 30 day -> HDBSCAN\n",
    "min_samples = 10, 50, 200\n",
    "데이터가 모자라는 경우 이전날짜의 데이터 편입\n",
    "json 저장, 형식:\n",
    "    {\n",
    "        {\n",
    "            \"Day\": YYYYMMDD (20191231인 경우(Window size == 30), 20191202 - 20191231의 데이터를 모은 것을 의미),\n",
    "            \"Cluster_{index}\": [IDs],\n",
    "            \"Cluster_{index}\": [IDs],\n",
    "            ...\n",
    "            \"Center_Link\": [Cluster_01의 대표 Link(Centroid와 가장 가까운 embedding의 Link), Cluster_02의 대표 Link],\n",
    "            \"Noise\": [IDs]\n",
    "        },\n",
    "        ...\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import hdbscan\n",
    "import json\n",
    "import os\n",
    "\n",
    "embedding_path = \"../Data/News/Embeddings\"\n",
    "file_dirs = [os.path.join(embedding_path, file) for file in os.listdir(embedding_path) if file.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_N = 30\n",
    "with open(f\"reference_{ref_N}.json\") as f:\n",
    "    reference = json.load(f)\n",
    "\n",
    "tmp = None\n",
    "ref_dict = {}\n",
    "for row in reference:\n",
    "    key = list(row.keys())[0]\n",
    "    file_value = row[key][-1]\n",
    "\n",
    "    if tmp is not None and file_value != tmp:\n",
    "        date_obj = datetime.strptime(key, \"%Y%m%d\") - timedelta(days=1)\n",
    "        # ref_dict[date_obj] = tmp\n",
    "        ref_dict[date_obj.strftime(\"%Y%m%d\")] = tmp\n",
    "\n",
    "    tmp = file_value\n",
    "\n",
    "date_list = [list(row.keys())[0] for row in reference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'20190630': '005930_2019_Q1.json',\n",
       " '20200129': '005930_2019_Q2.json',\n",
       " '20200630': '005930_2020_Q1.json',\n",
       " '20210129': '005930_2020_Q2.json',\n",
       " '20210729': '005930_2021_Q1.json',\n",
       " '20211231': '005930_2021_Q2.json',\n",
       " '20220630': '005930_2022_Q1.json',\n",
       " '20230129': '005930_2022_Q2.json',\n",
       " '20230630': '005930_2023_Q1.json',\n",
       " '20231231': '005930_2023_Q2.json',\n",
       " '20240630': '005930_2024_Q1.json',\n",
       " '20250129': '005930_2024_Q2.json'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(date, reference_data):\n",
    "    date = datetime.strptime(date, format=\"%Y%m%d\")\n",
    "\n",
    "    for base_date in reference_data.keys():\n",
    "        if date <= datetime.strptime(base_date, format=\"%Y%m%d\"):\n",
    "            load_file = reference_data[base_date]\n",
    "            break\n",
    "    \n",
    "    return load_file\n",
    "\n",
    "def HDBSCAN(\n",
    "        embeddings,\n",
    "        metric: str = 'cosine',\n",
    "        cluster_selection_method: str = \"eom\",\n",
    "        min_cluster_size = None\n",
    "    ):\n",
    "    if min_cluster_size:\n",
    "        min_cluster_size = embeddings.shape[0] // 10\n",
    "    clusterer = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=min_cluster_size,\n",
    "        metric=metric,\n",
    "        cluster_selection_method=cluster_selection_method\n",
    "    )\n",
    "\n",
    "    clusterer.fit(embeddings)\n",
    "    labels = clusterer.labels_\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IDEAs:\n",
    "    - 날짜별로 30일간의 embedding 벡터에 대해서 Cluster, Representative vector까지 구하는 것은 good.\n",
    "    - New cluster의 등장을 어떻게 표현하지?\n",
    "        => Representative vector들만 모아서, 그 벡터들의 alignment를 생각해보는 것은? => 그렇다면 기준이 있어야 하지\n",
    "            + t 시점의 represnetative vector과 t+1시점의 벡터가 서로 같다 / 다르다는 어떻게 하는가? : 당연히 metric 기반이겠지.\n",
    "            + 그러면 같다 다르다를 정하는 metric을 내가 임의로 저장해도 괜찮은가? X, 내가 실제로 저장하기도 어려워보이고...\n",
    "            + 그렇다면 t시점에 만들어진 cluster N개, t+1시점에 만들어진 cluster M개, 서로 vector간 distance metric 비교하면 N*M matrix\n",
    "            + Get minimum by row -> i-th(in time==t) cluster <~> j-th(in time==t+1) cluster Linked\n",
    "            + N > M인 경우, (N-M)개의 cluster: depreciated (한번에 사라지면 좀 그렇지? 그래서 patience를 도입하자)\n",
    "            + M > N인 경우, (M-N)개의 cluster: newly created\n",
    "            + Minimum distance와 patience를 어떻게 구할 수 있을지??\n",
    "            + patience = 3days >> 이정도가 지나도 distance가 threshold밑으로 내려가지 않으면 클러스터가 사라진 것으로 판단\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAYproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
